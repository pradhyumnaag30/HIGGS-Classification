{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910cdbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, accuracy_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.amp import GradScaler, autocast\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947c0d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load the dataset\n",
    "\n",
    "df = pd.read_csv(\"HIGGS_short.csv\")\n",
    "y = df[\"label\"].values.astype(np.float32)\n",
    "X = df.drop(columns=[\"label\"]).values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec74c7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Train/Val/Test Split (70/15/15)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.30, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.50, random_state=42, stratify=y_temp\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29e9a3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Dataset / Dataloaders\n",
    "\n",
    "class HiggsDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            torch.tensor(self.X[idx], dtype=torch.float32),\n",
    "            torch.tensor(self.y[idx], dtype=torch.float32),\n",
    "        )\n",
    "\n",
    "train_ds = HiggsDataset(X_train, y_train)\n",
    "val_ds   = HiggsDataset(X_val, y_val)\n",
    "test_ds  = HiggsDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=8192, shuffle=True, num_workers=0, pin_memory=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=8192, shuffle=False, num_workers=0, pin_memory=True)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=8192, shuffle=False, num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4eb5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Model Definition\n",
    "\n",
    "class ResidualSwiGLUBlock(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        self.fc1 = nn.Linear(dim, dim * 2)\n",
    "        self.fc2 = nn.Linear(dim, dim)\n",
    "\n",
    "        # LayerScale\n",
    "        self.layer_scale = nn.Parameter(0.1 * torch.ones(dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = self.norm(x)\n",
    "\n",
    "        # SwiGLU\n",
    "        a, b = self.fc1(x).chunk(2, dim=-1)\n",
    "        x = a * torch.sigmoid(b)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        # LayerScale\n",
    "        x = x * self.layer_scale\n",
    "\n",
    "        return residual + x\n",
    "\n",
    "\n",
    "class DeepMLP(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        hidden = 1536\n",
    "        depth = 10\n",
    "\n",
    "        self.input_layer = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden),\n",
    "            nn.LayerNorm(hidden),\n",
    "        )\n",
    "\n",
    "        self.blocks = nn.Sequential(\n",
    "            *[ResidualSwiGLUBlock(hidden) for _ in range(depth)]\n",
    "        )\n",
    "\n",
    "        self.output_layer = nn.Linear(hidden, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_layer(x)\n",
    "        x = self.blocks(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7408bc82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: cuda\n",
      "Device: cuda\n",
      "Model on: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# 5. Device + Model Initialization\n",
    "\n",
    "device = \"cuda\" #auto if no cuda\n",
    "print(\"Using:\", device)\n",
    "\n",
    "model = DeepMLP(X_train.shape[1]).to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-4)\n",
    "\n",
    "print(\"Device:\", device)\n",
    "print(\"Model on:\", next(model.parameters()).device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5a3f7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. LR Warmup + Cosine Annealing\n",
    "\n",
    "EPOCHS = 50\n",
    "total_steps = len(train_loader) * EPOCHS\n",
    "warmup_steps = int(total_steps * 0.2)\n",
    "\n",
    "def lr_lambda(step):\n",
    "    if step < warmup_steps:\n",
    "        return step / warmup_steps\n",
    "    progress = (step - warmup_steps) / (total_steps - warmup_steps)\n",
    "    return 0.5 * (1 + np.cos(np.pi * progress))\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2341a96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Model EMA\n",
    "\n",
    "class EMA:\n",
    "    def __init__(self, model, decay=0.999):\n",
    "        self.decay = decay\n",
    "        self.shadow = {k: v.clone().detach() for k, v in model.state_dict().items()}\n",
    "\n",
    "    def update(self, model):\n",
    "        for k, v in model.state_dict().items():\n",
    "            self.shadow[k] = self.decay * self.shadow[k] + (1 - self.decay) * v.detach()\n",
    "\n",
    "    def apply(self, model):\n",
    "        model.load_state_dict(self.shadow)\n",
    "\n",
    "ema = EMA(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d40a5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. GradScaler (CPU-safe)\n",
    "\n",
    "scaler = GradScaler(device=device)\n",
    "\n",
    "# 9. Validation Function\n",
    "\n",
    "def evaluate_auc(loader):\n",
    "    model.eval()\n",
    "    preds, trues = [], []\n",
    "\n",
    "    with torch.no_grad(), autocast(device_type=device):\n",
    "        for xb, yb in loader:\n",
    "            xb = xb.to(device)\n",
    "            yb = yb.to(device)\n",
    "\n",
    "            logits = model(xb)\n",
    "            prob = torch.sigmoid(logits)\n",
    "\n",
    "            preds.append(prob.cpu().numpy())\n",
    "            trues.append(yb.cpu().numpy())\n",
    "\n",
    "    return roc_auc_score(np.concatenate(trues), np.concatenate(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ccb78c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50: 100%|██████████| 939/939 [05:47<00:00,  2.70it/s, loss=0.591]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Validation AUC = 0.75037\n",
      "New Best Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50: 100%|██████████| 939/939 [05:55<00:00,  2.64it/s, loss=0.559]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Validation AUC = 0.79634\n",
      "New Best Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/50: 100%|██████████| 939/939 [05:54<00:00,  2.65it/s, loss=0.5]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Validation AUC = 0.82914\n",
      "New Best Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/50: 100%|██████████| 939/939 [05:50<00:00,  2.68it/s, loss=0.481]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Validation AUC = 0.84157\n",
      "New Best Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/50: 100%|██████████| 939/939 [05:39<00:00,  2.77it/s, loss=0.492]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Validation AUC = 0.84903\n",
      "New Best Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/50: 100%|██████████| 939/939 [05:46<00:00,  2.71it/s, loss=0.478]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Validation AUC = 0.85579\n",
      "New Best Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/50: 100%|██████████| 939/939 [05:59<00:00,  2.61it/s, loss=0.47] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Validation AUC = 0.85926\n",
      "New Best Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/50: 100%|██████████| 939/939 [05:57<00:00,  2.63it/s, loss=0.449]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Validation AUC = 0.86216\n",
      "New Best Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/50: 100%|██████████| 939/939 [05:49<00:00,  2.68it/s, loss=0.453]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Validation AUC = 0.86698\n",
      "New Best Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/50: 100%|██████████| 939/939 [05:48<00:00,  2.69it/s, loss=0.443]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Validation AUC = 0.87036\n",
      "New Best Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/50: 100%|██████████| 939/939 [05:46<00:00,  2.71it/s, loss=0.428]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Validation AUC = 0.87283\n",
      "New Best Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/50: 100%|██████████| 939/939 [05:47<00:00,  2.71it/s, loss=0.44] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 Validation AUC = 0.87522\n",
      "New Best Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/50: 100%|██████████| 939/939 [05:39<00:00,  2.77it/s, loss=0.415]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 Validation AUC = 0.87730\n",
      "New Best Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/50: 100%|██████████| 939/939 [05:39<00:00,  2.77it/s, loss=0.412]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 Validation AUC = 0.87798\n",
      "New Best Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/50: 100%|██████████| 939/939 [05:41<00:00,  2.75it/s, loss=0.407]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 Validation AUC = 0.87871\n",
      "New Best Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/50: 100%|██████████| 939/939 [05:44<00:00,  2.73it/s, loss=0.399]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 Validation AUC = 0.87779\n",
      "  No improvement (1/2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/50: 100%|██████████| 939/939 [05:46<00:00,  2.71it/s, loss=0.408]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 Validation AUC = 0.87797\n",
      "  No improvement (2/2)\n",
      "Early stopping!\n"
     ]
    }
   ],
   "source": [
    "# 10. Training Loop with Early Stopping\n",
    "\n",
    "PATIENCE = 2\n",
    "best_auc = 0\n",
    "counter = 0\n",
    "step = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "\n",
    "    for xb, yb in loop:\n",
    "        xb = xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with autocast(device_type=device):\n",
    "            logits = model(xb)\n",
    "            loss = criterion(logits, yb)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        scheduler.step()\n",
    "\n",
    "        # Update EMA after optimizer step\n",
    "        ema.update(model)\n",
    "        step += 1\n",
    "\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    val_auc = evaluate_auc(val_loader)\n",
    "    print(f\"Epoch {epoch+1} Validation AUC = {val_auc:.5f}\")\n",
    "\n",
    "    if val_auc > best_auc:\n",
    "        best_auc = val_auc\n",
    "        counter = 0\n",
    "\n",
    "        # Save both raw weights AND EMA weights\n",
    "        torch.save(model.state_dict(), \"best_raw.pt\")\n",
    "        torch.save(ema.shadow, \"best_ema.pt\")\n",
    "\n",
    "        print(\"New Best Model\")\n",
    "    else:\n",
    "        counter += 1\n",
    "        print(f\"  No improvement ({counter}/{PATIENCE})\")\n",
    "        if counter >= PATIENCE:\n",
    "            print(\"Early stopping!\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619c46a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================= FINAL MLP RESULTS =================\n",
      "ROC-AUC: 0.88525\n",
      "PR-AUC: 0.89509\n",
      "Accuracy: 0.79986\n",
      "====================================================\n"
     ]
    }
   ],
   "source": [
    "# 11. Final Evaluation (EMA weights)\n",
    "\n",
    "ema_weights = torch.load(\"best_ema.pt\")\n",
    "model.load_state_dict(ema_weights)\n",
    "\n",
    "model.eval()\n",
    "test_preds, test_trues = [], []\n",
    "\n",
    "with torch.no_grad(), autocast(device_type=device):\n",
    "    for xb, yb in test_loader:\n",
    "        xb = xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "        prob = torch.sigmoid(model(xb))\n",
    "        test_preds.append(prob.cpu().numpy())\n",
    "        test_trues.append(yb.cpu().numpy())\n",
    "\n",
    "test_preds = np.concatenate(test_preds)\n",
    "test_trues = np.concatenate(test_trues)\n",
    "\n",
    "auc = roc_auc_score(test_trues, test_preds)\n",
    "pr_auc = average_precision_score(test_trues, test_preds)\n",
    "acc = accuracy_score(test_trues, (test_preds > 0.5).astype(int))\n",
    "\n",
    "print(\"\\n================= FINAL MLP RESULTS =================\")\n",
    "print(\"ROC-AUC:\", round(auc, 5))\n",
    "print(\"PR-AUC:\", round(pr_auc, 5))\n",
    "print(\"Accuracy:\", round(acc, 5))\n",
    "print(\"====================================================\")\n",
    "\n",
    "torch.save(model.state_dict(), \"Models/DNN.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
