{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18ae3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2413b01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load the dataset\n",
    "\n",
    "df = pd.read_csv(\"HIGGS_short.csv\")\n",
    "\n",
    "# Target & Features\n",
    "y = df[\"label\"]\n",
    "X = df.drop(columns=[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89b84a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Train/Val/Test Split (70/15/15)\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.30, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.50, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "print(f\"Train: {X_train.shape}, Val: {X_val.shape}, Test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc40bf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Feature Importance generated by LightGBM\n",
    "\n",
    "feature_importances = {\n",
    "    \" m_bb\": 6374,\n",
    "    \" lepton  pT\": 4739,\n",
    "    \" m_wwbb\": 4497,\n",
    "    \" jet 1 pt\": 4345,\n",
    "    \" m_jlv\": 4162,\n",
    "    \" m_wbb\": 4140,\n",
    "    \" m_jj\": 3798,\n",
    "    \" m_jjj\": 3770,\n",
    "    \" jet 2 pt\": 3221,\n",
    "    \" jet 1 eta\": 2925,\n",
    "    \" missing energy magnitude\": 2797,\n",
    "    \" lepton  eta\": 2763,\n",
    "    \" jet 3 pt\": 2228,\n",
    "    \" jet 2 eta\": 2113,\n",
    "    \" m_lv\": 2020,\n",
    "    \" jet 4 pt\": 1768,\n",
    "    \" jet 3 eta\": 1576,\n",
    "    \" jet 1 b-tag\": 1433,\n",
    "    \" jet 4 eta\": 1327,\n",
    "    \" jet 2 b-tag\": 668\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb9be86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Function: Get Top-K features\n",
    "\n",
    "def get_top_k_features(feature_importances, K):\n",
    "    sorted_features = sorted(feature_importances.items(), key=lambda x: x[1], reverse=True)\n",
    "    return [f for f, _ in sorted_features[:K]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6d97e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Train model (LightGBM / XGBoost)\n",
    "\n",
    "def train_model(model_type, X_train, y_train, X_val, y_val):\n",
    "    \n",
    "    if model_type == \"lgbm\":\n",
    "        train_data = lgb.Dataset(X_train, label=y_train)\n",
    "        val_data   = lgb.Dataset(X_val,   label=y_val)\n",
    "\n",
    "        params = {\n",
    "            \"objective\": \"binary\",\n",
    "            \"metric\": \"auc\",\n",
    "            \"learning_rate\": 0.05,\n",
    "            \"num_leaves\": 64,\n",
    "            \"feature_fraction\": 0.9,\n",
    "            \"bagging_fraction\": 0.8,\n",
    "            \"bagging_freq\": 5,\n",
    "            \"verbose\": -1\n",
    "        }\n",
    "        \n",
    "        model = lgb.train(\n",
    "            params,\n",
    "            train_data,\n",
    "            num_boost_round=2000,\n",
    "            valid_sets=[val_data],\n",
    "            callbacks=[lgb.early_stopping(stopping_rounds=50)]\n",
    "        )\n",
    "        return model\n",
    "\n",
    "    elif model_type == \"xgb\":\n",
    "        train_d = xgb.DMatrix(X_train, label=y_train)\n",
    "        val_d   = xgb.DMatrix(X_val,   label=y_val)\n",
    "\n",
    "        params = {\n",
    "            \"objective\": \"binary:logistic\",\n",
    "            \"eval_metric\": \"auc\",\n",
    "            \"eta\": 0.05,\n",
    "            \"max_depth\": 8,\n",
    "            \"subsample\": 0.8,\n",
    "            \"colsample_bytree\": 0.9\n",
    "        }\n",
    "\n",
    "        model = xgb.train(\n",
    "            params,\n",
    "            train_d,\n",
    "            num_boost_round=2000,\n",
    "            evals=[(val_d, 'val')],\n",
    "            early_stopping_rounds=50,\n",
    "            verbose_eval=False\n",
    "        )\n",
    "        return model\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"model_type must be 'lgbm' or 'xgb'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457f6b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Evaluation\n",
    "\n",
    "def evaluate(model, model_type, X_test, y_test):\n",
    "\n",
    "    if model_type == \"lgbm\":\n",
    "        preds_proba = model.predict(X_test)\n",
    "    else:\n",
    "        preds_proba = model.predict(xgb.DMatrix(X_test))\n",
    "\n",
    "    preds = (preds_proba > 0.5).astype(int)\n",
    "\n",
    "    return {\n",
    "        \"AUC\": round(roc_auc_score(y_test, preds_proba), 5),\n",
    "        \"PR-AUC\": round(average_precision_score(y_test, preds_proba), 5),\n",
    "        \"Accuracy\": round(accuracy_score(y_test, preds), 5)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81526407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Run TOP-K experiment\n",
    "\n",
    "K = 20 # or lower\n",
    "model_type = \"xgb\"   # or \"xgb\"\n",
    "\n",
    "top_k_features = get_top_k_features(feature_importances, K)\n",
    "\n",
    "X_train_k = X_train[top_k_features]\n",
    "X_val_k   = X_val[top_k_features]\n",
    "X_test_k  = X_test[top_k_features]\n",
    "\n",
    "model = train_model(model_type, X_train_k, y_train, X_val_k, y_val)\n",
    "results = evaluate(model, model_type, X_test_k, y_test)\n",
    "\n",
    "print(f\"TOP-{K} RESULTS:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09992772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Save Model\n",
    "\n",
    "model.save_model(f\"Models/{model_type}_TOP{K}Features.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
